

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Get Started &mdash; PyTrx 1.2.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Package Guide" href="Guide.html" />
    <link rel="prev" title="Installation" href="Installation.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> PyTrx
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="Installation.html">Installation</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Get Started</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#automated-detection-of-supraglacial-lakes">Automated detection of supraglacial lakes</a></li>
<li class="toctree-l2"><a class="reference internal" href="#manual-detection-of-plume-footprints">Manual detection of plume footprints</a></li>
<li class="toctree-l2"><a class="reference internal" href="#manual-detection-of-terminus-profiles">Manual detection of terminus profiles</a></li>
<li class="toctree-l2"><a class="reference internal" href="#georectification-of-glacier-calving-event-point-locations">Georectification of glacier calving event point locations</a></li>
<li class="toctree-l2"><a class="reference internal" href="#sparse-feature-tracking">Sparse feature-tracking</a></li>
<li class="toctree-l2"><a class="reference internal" href="#dense-feature-tracking">Dense feature-tracking</a></li>
<li class="toctree-l2"><a class="reference internal" href="#sparse-and-dense-feature-tracking">Sparse and dense feature-tracking</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="Guide.html">Package Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="Packages.html">Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="Links.html">Links and Acknowledgements</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">PyTrx</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Get Started</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/GetStarted.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="get-started">
<h1>Get Started<a class="headerlink" href="#get-started" title="Permalink to this headline">¶</a></h1>
<p>PyTrx comes with working examples to get started with. These scripts are available in the PyTrx repository
<a class="reference external" href="https://github.com/PennyHow/PyTrx/tree/master/PyTrx/Examples">here</a>. These examples are for applications in glaciology, which can be adapted and used. We hope these are especially useful for beginners in coding.</p>
<div class="section" id="automated-detection-of-supraglacial-lakes">
<h2>Automated detection of supraglacial lakes<a class="headerlink" href="#automated-detection-of-supraglacial-lakes" title="Permalink to this headline">¶</a></h2>
<p>In this example, we will derived changes in surface area of supraglacial lakes captured from Kronebreen, Svalbard, for a small subset of the 2014 melt season. This example can be found in <a class="reference external" href="https://github.com/PennyHow/PyTrx/blob/master/PyTrx/Examples/KR_autoarea.py">KR_autoarea.py</a>.</p>
<p>We will automatically detect water on the glacier based on differences in pixel intensity and corrected for image distortion; using images from <a class="reference external" href="https://github.com/PennyHow/PyTrx/tree/master/PyTrx/Examples/images/KR3_2014_subset">Kronebreen camera 3</a> and the associated <a class="reference external" href="https://github.com/PennyHow/PyTrx/blob/master/PyTrx/Examples/camenv_data/camenvs/CameraEnvironmentData_KR3_2014.txt">camera environment data</a>.</p>
<p>First, we need to import os (for file checking and creation) and the PyTrx packages that we are going to use.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>

<span class="kn">from</span> <span class="nn">PyTrx.CamEnv</span> <span class="kn">import</span> <span class="n">CamEnv</span>
<span class="kn">from</span> <span class="nn">PyTrx.Area</span> <span class="kn">import</span> <span class="n">Area</span>
<span class="kn">from</span> <span class="nn">PyTrx.Velocity</span> <span class="kn">import</span> <span class="n">Homography</span>
<span class="kn">import</span> <span class="nn">PyTrx.FileHandler</span> <span class="kn">as</span> <span class="nn">FileHandler</span>
<span class="kn">from</span> <span class="nn">PyTrx.Utilities</span> <span class="kn">import</span> <span class="n">plotAreaPx</span><span class="p">,</span> <span class="n">pltAreaXYZ</span>
</pre></div>
</div>
<p>We load our camera environment and masks (for feature extraction and image registration), and set the paths to our input images and output folder.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define camera environment input file</span>
<span class="n">camdata</span> <span class="o">=</span> <span class="s1">&#39;../Examples/camenv_data/camenvs/CameraEnvironmentData_KR3_2014.txt&#39;</span>

<span class="c1"># Define feature detection and registration mask files</span>
<span class="n">camamask</span> <span class="o">=</span> <span class="s1">&#39;../Examples/camenv_data/masks/KR3_2014_amask.jpg&#39;</span>
<span class="n">caminvmask</span> <span class="o">=</span> <span class="s1">&#39;../Examples/camenv_data/invmasks/KR3_2014_inv.jpg&#39;</span>

<span class="c1"># Define image folder</span>
<span class="n">camimgs</span> <span class="o">=</span> <span class="s1">&#39;../Examples/images/KR3_2014_subset/*.JPG&#39;</span>

<span class="c1"># Define data output directory</span>
<span class="n">destination</span> <span class="o">=</span> <span class="s1">&#39;../Examples/results/KR_autoarea/&#39;</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">destination</span><span class="p">):</span>
    <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">destination</span><span class="p">)</span>
</pre></div>
</div>
<p>Next, we create a CamEnv object using our previously defined camera environment text file which contains information about the camera location and pose, and file paths to our DEM, ground control point positions, camera calibration coefficients, and reference image.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create camera environment</span>
<span class="n">cameraenvironment</span> <span class="o">=</span> <span class="n">CamEnv</span><span class="p">(</span><span class="n">camdata</span><span class="p">)</span>
</pre></div>
</div>
<p>If certain camera environment parameters are unknown or guessed, then PyTrx’s optimisation parameters can be used to refine the camera environment and improve the georectification. This refinement is conducted based on the ground control points.</p>
<p>In this case, the camera pose (yaw, pitch, roll - YPR) is unknown, so we will use the optimisation routine the refine the YPR values.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set camera optimisation parameters</span>

<span class="n">optparams</span> <span class="o">=</span> <span class="s1">&#39;YPR&#39;</span>      <span class="c1"># Flag to denote which parameters to optimise:</span>
                       <span class="c1"># YPR=camera pose; INT=intrinsic camera model;</span>
                       <span class="c1"># EXT=extrinsic camera model; ALL=all camera</span>
                       <span class="c1"># parameters</span>

<span class="n">optmethod</span> <span class="o">=</span> <span class="s1">&#39;trf&#39;</span>      <span class="c1"># Optimisation method: trf=Trust Region</span>
                       <span class="c1"># Reflective algorithm; dogbox=dogleg algorithm;</span>
                       <span class="c1"># lm=Levenberg-Marquardt algorithm</span>

<span class="c1"># Optimise camera</span>
<span class="n">cameraenvironment</span><span class="o">.</span><span class="n">optimiseCamEnv</span><span class="p">(</span><span class="n">optparams</span><span class="p">,</span> <span class="n">optmethod</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></div>
</div>
<p>In order to make measurements from the images, we need to ensure that motion in the camera platform is corrected for (otherwise we will see jumps in the positions of our detected lakes when the camera platform moves).</p>
<p>We will use PyTrx’s Homography object to track static features in the image and identify camera platform motion. We can subsequently use these movements to create a homography model and correct for this motion.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set homography parameters</span>
<span class="c1"># Homography tracking method - sparse or dense tracking</span>
<span class="n">hgmethod</span><span class="o">=</span><span class="s1">&#39;sparse&#39;</span>

<span class="c1"># Pt seeding parameters (max. pts, quality, min. distance</span>
<span class="n">hgseed</span> <span class="o">=</span> <span class="p">[</span><span class="mi">50000</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">]</span>

<span class="c1"># Tracking parameters (window size, backtracking threshold, min. num of pts)</span>
<span class="n">hgtrack</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">25</span><span class="p">,</span><span class="mi">25</span><span class="p">),</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>


<span class="c1"># Set up Homography object</span>
<span class="n">homog</span> <span class="o">=</span> <span class="n">Homography</span><span class="p">(</span><span class="n">camimgs</span><span class="p">,</span> <span class="n">cameraenvironment</span><span class="p">,</span> <span class="n">caminvmask</span><span class="p">,</span>
                   <span class="n">calibFlag</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">band</span><span class="o">=</span><span class="s1">&#39;L&#39;</span><span class="p">,</span> <span class="n">equal</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># Calculate homography</span>
<span class="n">hg</span> <span class="o">=</span> <span class="n">homog</span><span class="o">.</span><span class="n">calcHomographies</span><span class="p">([</span><span class="n">hgmethod</span><span class="p">,</span> <span class="n">hgseed</span><span class="p">,</span> <span class="n">hgtrack</span><span class="p">])</span>

<span class="c1"># Compile homography matrices from output</span>
<span class="n">homogmatrix</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">hg</span><span class="p">]</span>
</pre></div>
</div>
<p>Now we have our homography model, we can look at detecting lakes in the images. As we want the lake features as polygons, we will use PyTrx’s Area object to automatically identify these features. First, we will initialise the object with our images, camera environment object, homography model, and three flags denoting whether the images should be corrected for lens distortion, which pixel band should be used in the detection process (red, green, blue or grayscale), and whether the pixels in the images should be adjusted with histogram equalisation.</p>
<p>Lakes will be identified based on the difference in pixel intensities between the water and adjacent ice. The time-lapse images will also be enhanced to aid in identifying them.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set parameters to initialise Area object</span>
<span class="c1"># Detect with corrected or uncorrected images</span>
<span class="n">calibFlag</span> <span class="o">=</span> <span class="bp">True</span>

<span class="c1"># Pixel band to carry forward (&#39;R&#39;, &#39;G&#39;, &#39;B&#39; or &#39;L&#39;)</span>
<span class="n">imband</span> <span class="o">=</span> <span class="s1">&#39;R&#39;</span>

<span class="c1"># Images with histogram equalisation or not</span>
<span class="n">equal</span> <span class="o">=</span> <span class="bp">True</span>

<span class="c1"># Set up Area object</span>
<span class="n">lakes</span> <span class="o">=</span> <span class="n">Area</span><span class="p">(</span><span class="n">camimgs</span><span class="p">,</span> <span class="n">cameraenvironment</span><span class="p">,</span> <span class="n">homogmatrix</span><span class="p">,</span> <span class="n">calibFlag</span><span class="p">,</span> <span class="n">imband</span><span class="p">,</span> <span class="n">equal</span><span class="p">)</span>
</pre></div>
</div>
<p>We can set a number of detection parameters in our Area object to aid in the automated identification of lakes, including image enhancing, image masking, and setting athreshold for the number of detected polygons that will be retained.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set image enhancement parameters</span>
<span class="n">diff</span> <span class="o">=</span> <span class="s1">&#39;light&#39;</span>
<span class="n">phi</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">theta</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">lakes</span><span class="o">.</span><span class="n">setEnhance</span><span class="p">(</span><span class="n">diff</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">theta</span><span class="p">)</span>

<span class="c1"># Set mask and image number with maximum area of interest</span>
<span class="n">maxim</span> <span class="o">=</span> <span class="mi">0</span>                 <span class="n">t</span>
<span class="n">lakes</span><span class="o">.</span><span class="n">setMax</span><span class="p">(</span><span class="n">camamask</span><span class="p">,</span><span class="n">maxim</span><span class="p">)</span>

<span class="c1"># Set polygon threshold (i.e. number of polygons kept)</span>
<span class="n">threshold</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">lakes</span><span class="o">.</span><span class="n">setThreshold</span><span class="p">(</span><span class="n">threshold</span><span class="p">)</span>
</pre></div>
</div>
<p>Following this, we will use a pre-defined pixel value range to detect lakes from the images. In this case, pixel values between 1 and 8 will be classified as water. The calcAutoAreas function will then be executed to detect water through all the time-lapse images in our sequence.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set pixel colour range, from which extents will be distinguished</span>
<span class="n">maxcol</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">mincol</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">lakes</span><span class="o">.</span><span class="n">setColourrange</span><span class="p">(</span><span class="n">maxcol</span><span class="p">,</span> <span class="n">mincol</span><span class="p">)</span>
</pre></div>
</div>
<p>The calcAutoAreas function will then be executed to detect water through all the time-lapse images in our sequence. The colour and verify flags can be toggled for defining the pixel colour range in each image and verifying each identified polygon manually, respectively.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Calculate real areas</span>
<span class="n">areas</span> <span class="o">=</span> <span class="n">lakes</span><span class="o">.</span><span class="n">calcAutoAreas</span><span class="p">(</span><span class="n">colour</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">verify</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
</div>
<p>Now we have our detected lakes, we can plot them in both the image plane (u,v) and real-world coordinates (x,y,z) to see how they look using the plotting functions in the Utilities module.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Retrieve images and distortion parameters for plotting</span>
<span class="n">imgset</span><span class="o">=</span><span class="n">lakes</span><span class="o">.</span><span class="n">_imageSet</span>
<span class="n">cameraMatrix</span><span class="o">=</span><span class="n">cameraenvironment</span><span class="o">.</span><span class="n">getCamMatrixCV2</span><span class="p">()</span>
<span class="n">distortP</span><span class="o">=</span><span class="n">cameraenvironment</span><span class="o">.</span><span class="n">getDistortCoeffsCV2</span><span class="p">()</span>

<span class="c1"># Retrieve DEM array for plotting</span>
<span class="n">dem</span> <span class="o">=</span> <span class="n">cameraenvironment</span><span class="o">.</span><span class="n">getDEM</span><span class="p">()</span>

<span class="c1"># Retrieve uv and xyz coordinates of lakes</span>
<span class="n">uvpts</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">areas</span><span class="p">]</span>
<span class="n">xyzpts</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">areas</span><span class="p">]</span>

<span class="c1"># Show image extents and dems</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">areas</span><span class="p">)):</span>
    <span class="n">plotAreaPX</span><span class="p">(</span><span class="n">uvpts</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
               <span class="n">imgset</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">getImageCorr</span><span class="p">(</span><span class="n">cameraMatrix</span><span class="p">,</span> <span class="n">distortP</span><span class="p">),</span>
               <span class="n">show</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">save</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
    <span class="n">plotAreaXYZ</span><span class="p">(</span><span class="n">xyzpts</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">dem</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">save</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</pre></div>
</div>
<p>And finally, we can export our identified lakes as both text files and shapefiles using the writing functions in the FileHandler module.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get all image names for reference</span>
<span class="n">imn</span> <span class="o">=</span> <span class="n">lakes</span><span class="o">.</span><span class="n">getImageNames</span><span class="p">()</span>

<span class="c1"># Get pixel and sq m lake areas</span>
<span class="n">uvareas</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">areas</span><span class="p">]</span>
<span class="n">xyzareas</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">areas</span><span class="p">]</span>


<span class="c1"># Write areas to text file</span>
<span class="n">FileHandler</span><span class="o">.</span><span class="n">writeAreaFile</span><span class="p">(</span><span class="n">uvareas</span><span class="p">,</span> <span class="n">xyzareas</span><span class="p">,</span> <span class="n">imn</span><span class="p">,</span> <span class="n">destination</span><span class="o">+</span><span class="s1">&#39;areas.csv&#39;</span><span class="p">)</span>

<span class="c1"># Write area coordinates to text file</span>
<span class="n">FileHandler</span><span class="o">.</span><span class="n">writeAreaCoords</span><span class="p">(</span><span class="n">uvpts</span><span class="p">,</span> <span class="n">xyzpts</span><span class="p">,</span> <span class="n">imn</span><span class="p">,</span>
                            <span class="n">destination</span><span class="o">+</span><span class="s1">&#39;uvcoords.txt&#39;</span><span class="p">,</span>
                            <span class="n">destination</span><span class="o">+</span><span class="s1">&#39;xyzcoords.txt&#39;</span><span class="p">)</span>

<span class="c1"># Write lakes to shapefiles with WGS84 projection</span>
<span class="n">proj</span> <span class="o">=</span> <span class="mi">32633</span>
<span class="n">FileHandler</span><span class="o">.</span><span class="n">writeAreaSHP</span><span class="p">(</span><span class="n">xyzpts</span><span class="p">,</span> <span class="n">imn</span><span class="p">,</span> <span class="n">destination</span><span class="o">+</span><span class="s1">&#39;shpfiles/&#39;</span><span class="p">,</span> <span class="n">proj</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="manual-detection-of-plume-footprints">
<h2>Manual detection of plume footprints<a class="headerlink" href="#manual-detection-of-plume-footprints" title="Permalink to this headline">¶</a></h2>
<p>Manual detection of meltwater plume extents, <em>KR_manualarea.py</em></p>
<p>Example driver for calculating meltwater plume surface extent at Kronebreen, Svalbard, for a small subset of the 2014 melt season. Specifically this script performs manual detection of meltwater plumes through sequential images of the glacier to derive surface areas which have been corrected for image distortion. Images are imported from those found in the ‘KR1_2014_subset’ folder, and the camera environment associated with the text file ‘CameraEnvironmentData_KR1_2014.txt’</p>
</div>
<div class="section" id="manual-detection-of-terminus-profiles">
<h2>Manual detection of terminus profiles<a class="headerlink" href="#manual-detection-of-terminus-profiles" title="Permalink to this headline">¶</a></h2>
<p>Manual detection of glacier terminus profiles, <em>TU_manualline.py</em></p>
<p>Example driver for calculating terminus profiles (as line features) at Tunabreen, Svalbard, for a small subset of the 2015 melt season using modules in PyTrx. This script performs manual detection of terminus position through sequential images of the glacier to derive line profiles which have been corrected for image distortion. Images are imported from those found in the ‘TU2_2015_subset’ folder, and the camera environment associated with the text file ‘CameraEnvironmentData_TU2_2014.txt’</p>
</div>
<div class="section" id="georectification-of-glacier-calving-event-point-locations">
<h2>Georectification of glacier calving event point locations<a class="headerlink" href="#georectification-of-glacier-calving-event-point-locations" title="Permalink to this headline">¶</a></h2>
<p>Georectification of calving event point locations, <em>TU_ptsgeorectify.py</em></p>
<p>Example driver which demonstrates the capabilities of the georectification functions provided in PyTrx (which are based upon those available in ImGRAFT). Pre-defined points are imported which denote calving events at Tunabreen, Svalbard, that have been distinguished in the image plane. These are subsequently projected to xyz locations using the georectification functions in PyTrx. The xyz locations are plotted onto the DEM, with the colour of each point denoting the style of calving in that particular instance. The xyz locations are finally exported as a text file (.txt) and as a shape file (.shp).</p>
</div>
<div class="section" id="sparse-feature-tracking">
<h2>Sparse feature-tracking<a class="headerlink" href="#sparse-feature-tracking" title="Permalink to this headline">¶</a></h2>
<p>Glacier velocities derived through feature-tracking of sparse points, <em>KR_velocity1.py</em></p>
<p>Example driver for deriving sparse velocities from Kronebreen, Svalbard, for a small subset of the 2014 melt season. Specifically this script performs feature-tracking through sequential daily images of the glacier to derive surface velocities (spatial average, individual point displacements and interpolated velocity maps) which have been corrected for image distortion and motion in the camera platform (i.e. image registration). This script uses images from those found in the ‘KR2_2014_subset’ folder, and camera environment data associated with the text file ‘CameraEnvironmentData_KR2_2014.txt’.</p>
</div>
<div class="section" id="dense-feature-tracking">
<h2>Dense feature-tracking<a class="headerlink" href="#dense-feature-tracking" title="Permalink to this headline">¶</a></h2>
<p>Glacier velocities derived through feature-tracking of dense grid, <em>KR_velocity2.py</em></p>
<p>Example driver for deriving dense velocities from Kronebreen, Svalbard, for a small subset of the 2014 melt season. Specifically this script performs feature-tracking through sequential daily images of the glacier to derive surface velocities (spatial average, individual point displacements and interpolated velocity maps) which have been corrected for image distortion and motion in the camera platform (i.e. image registration). This script uses images from those found in the ‘KR2_2014_subset’ folder, and camera environment data associated with the text file ‘CameraEnvironmentData_KR2_2014.txt’.</p>
</div>
<div class="section" id="sparse-and-dense-feature-tracking">
<h2>Sparse and dense feature-tracking<a class="headerlink" href="#sparse-and-dense-feature-tracking" title="Permalink to this headline">¶</a></h2>
<p>Alternative script for glacier velocity feature-tracking with both the sparse and dense methods, <em>KR_velocity3.py</em></p>
<p>Extended example driver for deriving velocities from Kronebreen, Svalbard, for a small subset of the 2014 melt season. This script produces the same outputs as <em>KR_velocity1.py</em> and <em>KR_velocity2.py</em>. The difference is that velocities are processed using the stand-alone functions provided in PyTrx, rather than handled by PyTrx’s class objects. This provides the user with a script that is more flexible and adaptable.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="Guide.html" class="btn btn-neutral float-right" title="Package Guide" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="Installation.html" class="btn btn-neutral float-left" title="Installation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2022, Penelope How

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>